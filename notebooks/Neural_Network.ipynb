{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Motor de redes neuronales\n",
    "\n",
    "En el siguiente notebook explicamos la funcionalidad que se llevado a cabo para hacer el motor de redes neuronales."
   ],
   "id": "169ed811dfeb2460"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "En primer lugar, se crea la instancia llamando a los modulos pertinentes que contienen las implementaciones. Hemos intentado hacer una buena separación en módulos para mejorar, no solo el orden, sino también la claridad del código a la hora de usarlo sin necesidad de estar poniendo muchos comentarios, ya que eso es una mala práctica a la larga.",
   "id": "7cb94fc8a4d93c93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np",
   "id": "a41550427c51f0b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.neural_network.neural_network import train, predict, create_nn, test_nn\n",
    "from src.neural_network.utils.draw_nn import draw_nn\n",
    "from src.neural_network.layers.activation.functions import Relu, Tanh, LeakyRelu\n",
    "from src.neural_network.utils.graphics.regression import learning_curve, dispersion_graph\n",
    "from src.neural_network.optimizers.sgd import SGD\n",
    "from src.neural_network.optimizers.adam import Adam\n",
    "from src.neural_network.optimizers.adagrad import Adagrad\n",
    "from src.neural_network.losses.categorical_cross_entropy import CategoricalCrossEntropyLoss\n",
    "from src.neural_network.losses.mse import MSELoss\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "e6f6b6d514075e5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizers = [\n",
    "    Adagrad(learning_rate=0.07),\n",
    "    Adagrad(learning_rate=0.07),\n",
    "    Adagrad(learning_rate=0.07)\n",
    "]\n",
    "\n",
    "activations = [LeakyRelu(alpha=0.017), LeakyRelu(alpha=0.017), LeakyRelu(alpha=0.017)]\n",
    "\n",
    "nn = create_nn([10, 8, 8, 3], activation_function=activations, optimizers=optimizers)"
   ],
   "id": "8a5f57c50bff8151"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "draw_nn(nn)\n",
   "id": "ecd6d601120a538b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Entrenamiento\n",
    "\n",
    "La función **train** devuelve un historial del valor de pérdida durante el entrenamiento para poder hacer gráficas como las que se verán en las siguientes celdas.\n",
    "\n",
    "\n",
    "Como parámetros necesita:\n",
    "- La Red Neuronal\n",
    "- La función de pérdida\n",
    "- La derivada de la función de pérdida\n",
    "- Los conjuntos de datos X, y\n",
    "- Opcionalmente: Número de epochs, learning_rate y optimizador.\n",
    "\n",
    "\n",
    "Es preciso que las variables X, y sean pasadas como arrays de numpy y tenga el siguiente shape:\n",
    "\n",
    "- X.shape = (n_samples, n_features, 1)\n",
    "- Y.shape = (n_samples, 1)\n",
    "\n",
    "Esto se debe a que la red espera como datos de entrada un vector columna.\n",
    "\n",
    "(Para simplicidad de la explicación vamos un conjunto de \n",
    "datos muy reducido tanto para entrenamiento como prueba, los experimentos reales se encuentran en el notebook testing de la carpeta tests)"
   ],
   "id": "176152381f82725b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 1, 0], [1, 1, 1], [0, 1, 1]])\n",
    "y_train = np.array([[0], [1], [1], [1], [0], [0], [0]])\n",
    "\n",
    "X_train = X_train.reshape((7, 3, 1))\n",
    "y_train = y_train.reshape((7, 1))\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ],
   "id": "734ebff4b454dbd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cargar el archivo .npz\n",
    "data = np.load('../data/datasets/iris.npz')\n",
    "\n",
    "# Ver qué arrays contiene\n",
    "print(\"Arrays en el archivo:\", data.files)\n",
    "\n",
    "x = data['X']   # características\n",
    "y = data['y']   # etiquetas\n",
    "\n",
    "\n",
    "X_train, X_provisional, y_train, y_provisional = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.3,       # proporción del dataset para test (20%)\n",
    "    train_size=0.7,     # opcional, se deduce de test_size si no se especifica\n",
    "    random_state=1,     # semilla para reproducibilidad\n",
    "    shuffle=True,        # si se baraja antes de dividir\n",
    ")\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_provisional, y_provisional,\n",
    "    test_size=0.5,       # proporción del dataset para test (20%)\n",
    "    train_size=0.5,     # opcional, se deduce de test_size si no se especifica\n",
    "    random_state=1,     # semilla para reproducibilidad\n",
    "    shuffle=True,        # si se baraja antes de dividir\n",
    ")\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test  = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "X_val   = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "\n",
    "print(f\"Train shape: x={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test shape: x={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Validation shape: x={X_val.shape}, y={y_val.shape}\")\n"
   ],
   "id": "6087e18c32be369"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hiperparámetros\n",
    "epochs = 700\n",
    "lr = 0.01\n",
    "# batch_size ="
   ],
   "id": "684f4ce0a0fde7ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizers = [Adam(learning_rate=lr),\n",
    "              Adam(learning_rate=lr)]\n",
    "\n",
    "activations = [Tanh(), Tanh()]\n",
    "\n",
    "nn = create_nn([4, 8, 3], activation_function=activations, optimizers=optimizers)\n",
    "\n",
    "#loss = CrossEntropyLoss()\n",
    "loss = CategoricalCrossEntropyLoss()\n",
    "\n",
    "train_loss = train(nn, loss, X_train, y_train, epochs=epochs)"
   ],
   "id": "8ad59e23179ac014"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1# Evaluación (Test)\n",
    "Nos preguntamos: ¿La red realmente aprendió algo útil, o solo imitó los datos del entrenamiento?\n",
    "\n",
    "Una vez entrenada la red, es necesario evaluar su rendimiento utilizando un conjunto de muestras que no haya visto anteriormente. Esto nos permite comprobar si el modelo ha aprendido patrones generales y no simplemente memorizado los datos de entrenamiento (lo que se conoce como overfitting).\n",
    "\n",
    "Para ello, basta con ejecutar una celda similar a la siguiente:\n",
    "\n",
    "```bash\n",
    "y_pred = predict(nn, X_test)\n",
    "```\n",
    "\n",
    "La variable y_pred contendrá las predicciones generadas por la red para cada una de las entradas del conjunto de prueba (X_test).\n",
    "Comparando estas predicciones con los valores reales (y_test), podremos medir la precisión del modelo o analizar visualmente qué tan bien se aproxima a la solución esperada."
   ],
   "id": "b20b2a29bb3d972f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "_, _ = test_nn(nn, X_train, y_train)",
   "id": "8c94938beef3b90c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = []\n",
    "for X, y in zip(X_train, y_train):\n",
    "    output = predict(nn, X)\n",
    "    y_pred.append(output)\n",
    "    print(f'Pred: {output[0]}, Actual: {y}')"
   ],
   "id": "898c6010392611c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A continuación se muestra la evolución de la pérdida durante el entrenamiento, lo cual nos permite observar cómo la red va ajustando sus parámetros para reducir el error. Una curva de pérdida que desciende de forma estable suele indicar que el modelo está aprendiendo correctamente.\n",
    "\n",
    "Además, se presenta un gráfico de dispersión que compara los valores predichos por la red frente a los valores reales.\n",
    "Si la red ha aprendido bien, los puntos deberían alinearse aproximadamente sobre la diagonal, lo que significa que las predicciones se aproximan a los valores esperados."
   ],
   "id": "52aaafe4b01b50cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "learning_curve(train_loss)",
   "id": "e715d432b9ef08a8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# ¿Qué nos dice esta gráfica?\n",
    "\n",
    "La línea muestra cómo la pérdida va bajando durante el entrenamiento.\n",
    "Al principio el error es alto, pero disminuye rápido, lo que significa que la red está aprendiendo.\n",
    "\n",
    "Luego la curva se aplana y se mantiene casi constante, indicando que el modelo ya ha aprendido todo lo importante y ha llegado a un punto estable.\n",
    "\n",
    "En resumen:\n",
    "La red ha aprendido bien y hace buenas predicciones sobre los datos de entrenamiento."
   ],
   "id": "16f1bea4a9561652"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
